{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MedBot Model Download\n",
        "\n",
        "**IMPORTANT**: Run this notebook AFTER you've completed training your MedBot in the main training notebook.\n",
        "\n",
        "This notebook will:\n",
        "1. Save your trained model properly\n",
        "2. Create a ZIP file for download\n",
        "3. Download the model to your computer\n",
        "4. Test the model to ensure it works\n",
        "\n",
        "**Prerequisites**: Make sure you have `model` and `tokenizer` variables from your training notebook."
      ],
      "metadata": {
        "id": "model_download_intro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save your fine-tuned model and tokenizer\n",
        "print(\"üîÑ Saving your trained MedBot model...\")\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./medbot_model\")\n",
        "tokenizer.save_pretrained(\"./medbot_model\")\n",
        "\n",
        "print(\"‚úÖ Model saved to ./medbot_model/\")\n",
        "\n",
        "# List the saved files\n",
        "import os\n",
        "print(\"\\nüìÅ Saved model files:\")\n",
        "total_size = 0\n",
        "for file in os.listdir(\"./medbot_model\"):\n",
        "    file_path = f\"./medbot_model/{file}\"\n",
        "    if os.path.isfile(file_path):\n",
        "        size = os.path.getsize(file_path) / (1024*1024)  # Size in MB\n",
        "        total_size += size\n",
        "        print(f\"  {file} - {size:.1f} MB\")\n",
        "\n",
        "print(f\"\\nüìä Total model size: {total_size:.1f} MB\")"
      ],
      "metadata": {
        "id": "save_model_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ZIP file of your model for easy download\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "print(\"üì¶ Creating ZIP file for download...\")\n",
        "\n",
        "def create_model_zip():\n",
        "    zip_filename = \"medbot_trained_model.zip\"\n",
        "    \n",
        "    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        # Add all files from medbot_model directory\n",
        "        for root, dirs, files in os.walk(\"./medbot_model\"):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arc_path = os.path.relpath(file_path, \".\")\n",
        "                zipf.write(file_path, arc_path)\n",
        "                print(f\"  Added: {file}\")\n",
        "    \n",
        "    print(f\"‚úÖ Created {zip_filename}\")\n",
        "    return zip_filename\n",
        "\n",
        "zip_file = create_model_zip()\n",
        "\n",
        "# Show file size\n",
        "zip_size = os.path.getsize(zip_file) / (1024*1024)\n",
        "print(f\"üìä ZIP file size: {zip_size:.1f} MB\")"
      ],
      "metadata": {
        "id": "create_zip_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your model to make sure it works before download\n",
        "print(\"üß™ Testing your trained model...\")\n",
        "\n",
        "import torch\n",
        "\n",
        "# Test with a sample medical question\n",
        "test_question = \"What are the symptoms of diabetes?\"\n",
        "\n",
        "# Generate response\n",
        "inputs = tokenizer.encode(test_question, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        inputs, \n",
        "        max_length=inputs.shape[1] + 100,\n",
        "        temperature=0.7,\n",
        "        do_sample=True,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        repetition_penalty=1.1,\n",
        "        no_repeat_ngram_size=3\n",
        "    )\n",
        "\n",
        "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(f\"\\n‚ùì Question: {test_question}\")\n",
        "print(f\"ü§ñ Model Response: {response}\")\n",
        "print(\"\\n‚úÖ Your model is working! Ready for download.\")"
      ],
      "metadata": {
        "id": "test_model_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the model ZIP file to your computer\n",
        "from google.colab import files\n",
        "\n",
        "print(\"‚¨áÔ∏è Downloading your trained MedBot model...\")\n",
        "print(\"This will download a ZIP file containing all your model files.\")\n",
        "print(\"Extract this ZIP and copy the contents to your deployment/models/ folder.\")\n",
        "\n",
        "# Download the ZIP file\n",
        "files.download(\"medbot_trained_model.zip\")\n",
        "\n",
        "print(\"‚úÖ Download started!\")\n",
        "print(\"\\nüöÄ Next steps after download:\")\n",
        "print(\"1. Extract medbot_trained_model.zip\")\n",
        "print(\"2. Copy all extracted files to your medbot-deployment/models/ folder\")\n",
        "print(\"3. Commit and push to GitHub\")\n",
        "print(\"4. Redeploy your app - it will use your trained model!\")\n",
        "print(\"\\nüìù Commands to run on your local machine:\")\n",
        "print(\"cd /home/serah/medbot-deployment\")\n",
        "print(\"rm -rf models/*\")\n",
        "print(\"# Extract your ZIP and copy files to models/\")\n",
        "print(\"git add models/\")\n",
        "print(\"git commit -m 'Add trained MedBot model'\")\n",
        "print(\"git push origin main\")\n",
        "print(\"# Then redeploy on Render\")"
      ],
      "metadata": {
        "id": "download_model_cell"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
